[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Comparison of spontaneous Raman spectrometers –",
    "section": "",
    "text": "AI usage disclosure\n\n\n\n\n\nWe used ChatGPT to help write code and help clarify and streamline text that we wrote. We also used Claude to help write code and help clarify and streamline text that we wrote."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Comparison of spontaneous Raman spectrometers –",
    "section": "Motivation",
    "text": "Motivation\nAt Arcadia, we’re interested in using spontaneous Raman spectroscopy as an agnostic, high-throughput tool for biological phenotyping. To implement this approach effectively, we evaluated a variety of Raman spectroscopy systems to determine which would best align with our research requirements. By testing the same research-relevant specimens across all instruments, we could directly compare their performance characteristics, including resolution, sensitivity, and signal-to-noise ratios under real experimental conditions. To facilitate data processing and characterization, we also created an open-source Python package, ramanalysis, to process, normalize, and help interpret the spectral data from different manufacturers. We hope that others getting started with similar systems can use this notebook and the open-source Python package associated with it to assist in their analyses. Our analysis has several caveats based on the acquisition parameters and samples we used, and as such, isn’t intended to generate a definitive ranking or absolute comparison of the instruments themselves."
  },
  {
    "objectID": "index.html#instrumentation",
    "href": "index.html#instrumentation",
    "title": "Comparison of spontaneous Raman spectrometers –",
    "section": "Instrumentation",
    "text": "Instrumentation\nOur goal for this study was to test a variety of spontaneous Raman systems with various capabilities to determine which instrument is best suited for our samples and applications. In total, we tested five different systems:\n\nHoriba MacroRAM\nRenishaw inVia Qontor\nWasatch WP 785X\nWasatch WP 532X\nOpenRAMAN\n\nPrior to the collection of a full dataset, we conducted preliminary measurements on a subset of samples to calibrate and optimize the acquisition parameters for each spectrometer. We provide these acquisition parameters in the tables below. For each sample, the laser power listed in the tables is either provided by the instrument or measured at the sample surface. Unless stated otherwise, we focused the laser spot by eye when obtaining measurements and collected spectra from cells growing on agar plates. Note that the OpenRAMAN is a spectrometer we’ve previously used and described in our research (Avasthi et al., 2024; Braverman et al., 2025)."
  },
  {
    "objectID": "index.html#sec-sampleprep",
    "href": "index.html#sec-sampleprep",
    "title": "Comparison of spontaneous Raman spectrometers –",
    "section": "Sample preparation",
    "text": "Sample preparation\n\nAcetonitrile\nWe chose acetonitrile, a common organic solvent, as a reference material for calibration. It has multiple easily resolvable, well-documented peaks in regions of Raman spectra relevant to our sample set. We used acetonitrile, ≥ 99.5% from Avantor/VWR, and analyzed it in a capped quartz cuvette.\n\n\nChlamydomonas strains\nWe compared three wild-type strains of Chlamydomonas grown on two types of solid media for a total of six treatments. There were two strains of Chlamydomonas reinhardtii, CC-124 (mating type -) and CC-125 (mating type +), and one strain of Chlamydomonas smithii, CC-1373 (mating type +).\n\n\nMedia Components\nWe made all solid media with 1.5% agar. We made “water” plates with ultrapure water from a Milli-Q EQ 7008 system equipped with a 0.22 μm filter. Individual media components are as follows:\n\nTAP (tris-acetate-phosphate) media\nWe purchased complete liquid media from UTEX.\nM-N (minimal media lacking nitrogen) media\nMade in-house following the above protocol.\n\n\n\nProtocols\nWe maintained cells on TAP or M-N media plates with 1.5% agar under a 12/12 hr light-dark cycle1 at ambient temperature for 5–15 days before use. Cells were densely streaked to cover about half of the plate, creating a lawn. To acquire spectra from cells, we focused the laser on the portion of the plate with cells. To acquire background spectra from media and agar, we focused the laser on the area without cells.\n1 Note that we didn’t account for the timing within the light phase of the cycle when measurements were taken.\n\n\n\n\n\n\nLayout of Chlamydomonas plates.\n\n\nTo prepare slides with cells for microscopy (this was done only for the Renishaw InVa Qontor), we drew a wax circle on a #1.5 glass coverslip to create a hydrophobic barrier for each sample, making six total. We pipetted 3 µL of either liquid TAP or M-N media within the wax circles, resulting in three coverslips with each media type. We then transferred a small number of cells to the liquid droplet using a clean pipette. After transfer, clumps of cells were removed with forceps, resulting in a more continuous distribution of cells in each droplet. We repeated this for each of the three strains. Then, using forceps, we flipped each coverslip, placed it onto an ethanol-cleaned glass slide, and sealed each edge with melted VALAP (1:1:1 mixture of Vaseline, lanolin, and paraffin wax) using a paintbrush."
  },
  {
    "objectID": "index.html#analysis-results",
    "href": "index.html#analysis-results",
    "title": "Comparison of spontaneous Raman spectrometers –",
    "section": "Analysis & results",
    "text": "Analysis & results\n\nCharacterizing spectral resolution with acetonitrile\nWe acquired and analyzed measurements of the same sample of acetonitrile on each instrument to assess system performance. By analyzing the spectra and comparing them to established references, we’re able to characterize each instrument’s approximate spectral resolution and accuracy (the accuracy of the observed peak positions with respect to reference peaks).\nWe’ll start by loading the acetonitrile spectrum from each instrument as well as the standard Raman peaks for acetonitrile (Shimanouchi, 1972). While five standard peaks are listed in the NIST database as medium, strong, or very strong, the peak at 2999 cm-1 can be hard to detect, particularly with 532 nm excitation. For this reason, we’ll only characterize the four most prominent peaks and fit each with a Voigt model2 (a convolution of a Gaussian distribution with a Lorentzian distribution) with a window size of 25.\n2 A Voigt profile is commonly used in peak fitting applications within spectroscopy because it accurately models spectral line shapes by accounting for both Doppler broadening (Gaussian component, due to thermal motion) and Lorentzian broadening (from collisional or lifetime effects). This makes it ideal for fitting experimental spectra where multiple broadening mechanisms contribute to the observed peak shape.\nfrom analysis.load_spectra import load_acetonitrile_spectra\nfrom lmfit.models import VoigtModel\nfrom ramanalysis.calibrate import ACETONITRILE_PEAKS_CM1\n\n# Load acetonitrile spectra and their corresponding spectrometers\nacetonitrile_spectra, acetonitrile_dataframe = load_acetonitrile_spectra()\n\n# Set parameters for peak finding\nnum_peaks = 4\nwindow_size = 25\nwavenumber_range_cm1 = (750, 3100)\n\nFigure 1 shows the results of the peak fitting. Because the quartz cuvette of acetonitrile yields relatively strong and clean spectra, very little preprocessing is applied to the spectra. If you expand the code cell below, you’ll see that the only preprocessing steps applied are cropping the spectra to the wavenumber range (750–3100 cm-1) and min-max normalization. Only the OpenRAMAN spectrum is smoothed via median filtering to suppress hot pixels and read noise from the detector.\n\n\n\n\n\n\nNote\n\n\n\nAnother strategy to deal with hot pixels from our acquisition would have been to acquire and subtract a dark spectrum (a spectrum with the laser powered off) to capture only the detector’s fixed pattern noise.\n\n\n\n\nSource code for this figure:\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom analysis.plotting import darken, get_custom_colorpalette, get_default_plotly_layout\nfrom plotly.subplots import make_subplots\nfrom ramanalysis.peak_fitting import find_n_most_prominent_peaks\n\n# Store peak fitting results\npeak_fitting_records = []\n\n# Create figure\ncolor_palette = get_custom_colorpalette()\nnum_rows = acetonitrile_dataframe.groupby([\"λ_nm\"]).count()[\"instrument\"].max().item()\nnum_cols = acetonitrile_dataframe[\"λ_nm\"].nunique()\nfig = make_subplots(\n    rows=num_rows,\n    cols=num_cols,\n    shared_xaxes=True,\n    shared_yaxes=True,\n    horizontal_spacing=0.02,\n    vertical_spacing=0.05,\n    column_titles=[\"785 nm\", \"532 nm\"],\n)\n\n# Map each (instrument, wavelength) combo to a subplot\nsubplot_indices = {  # (instrument, λ_nm) -&gt; (col, row)\n    (\"horiba\", 785): (1, 1),\n    (\"renishaw\", 785): (1, 2),\n    (\"wasatch\", 785): (1, 3),\n    (\"openraman\", 532): (2, 2),\n    (\"wasatch\", 532): (2, 3),\n}\n\nfor i, dataframe_row in acetonitrile_dataframe.iterrows():\n    # Get the raw spectrum and the instrument and wavelength with which it was recorded\n    wavelength_nm = dataframe_row[\"λ_nm\"]\n    instrument = dataframe_row[\"instrument\"]\n    raw_spectrum = acetonitrile_spectra[i]\n    subplot_col, subplot_row = subplot_indices[(instrument, wavelength_nm)]\n\n    # Apply median filtering on OpenRAMAN data to filter out hot pixels from the detector\n    if instrument == \"openraman\":\n        raw_spectrum = raw_spectrum.smooth(kernel_size=3)\n    # Crop and normalize spectra for peak detection\n    preprocessed_spectrum = raw_spectrum.between(*wavenumber_range_cm1).normalize()\n\n    # Plot each acetonitrile spectrum\n    name = f\"{instrument.capitalize()}\"\n    fig.add_trace(\n        go.Scatter(\n            x=preprocessed_spectrum.wavenumbers_cm1,\n            y=preprocessed_spectrum.intensities,\n            name=name,\n            hoverinfo=\"skip\",\n            marker={\"color\": color_palette[(instrument, wavelength_nm)]},\n        ),\n        row=subplot_row,\n        col=subplot_col,\n    )\n\n    # Find and get the indices of the most prominent peaks in the spectrum\n    peak_indices = find_n_most_prominent_peaks(\n        preprocessed_spectrum.intensities, num_peaks=num_peaks\n    )\n    for i_peak in peak_indices:\n        # Create window around each peak\n        peak_cm1, peak_height = preprocessed_spectrum.interpolate(i_peak)\n        window_range = (i_peak - window_size / 2, i_peak + window_size / 2)\n        window = np.linspace(*window_range, num=500)\n        # Interpolate the window along the spectrum\n        x_data_cm1, y_data = preprocessed_spectrum.interpolate(window)\n\n        # Fit the model to each peak\n        model = VoigtModel()\n        initial_fit_params = model.make_params(amplitude=1, center=peak_cm1, sigma=1, gamma=0.5)\n        fit_result = model.fit(y_data, initial_fit_params, x=x_data_cm1)\n\n        # Find the offset from acetonitrile reference peaks\n        peak_center = fit_result.params[\"center\"].value\n        reference_peak_index = np.abs(ACETONITRILE_PEAKS_CM1 - peak_center).argmin()\n        reference_peak = ACETONITRILE_PEAKS_CM1[reference_peak_index]\n        offset = peak_center - reference_peak\n\n        # Record the peak fitting results\n        peak_fitting_results = {**dataframe_row.to_dict(), **fit_result.params.valuesdict()}\n        peak_fitting_results[\"reference\"] = reference_peak\n        peak_fitting_results[\"offset\"] = offset\n        peak_fitting_records.append(peak_fitting_results)\n\n        # Plot and annotate each peak\n        annotation_text = f\"{peak_fitting_results['fwhm']:.1f} cm&lt;sup&gt;-1&lt;/sup&gt;\"\n        hovertext_fields = [\"fwhm\", \"height\", \"offset\"]\n        hovertext = [\n            f\"{field}: {peak_fitting_results[field]:.3g}&lt;br&gt;\" for field in hovertext_fields\n        ]\n        fig.add_trace(\n            go.Scatter(\n                x=[peak_center],\n                y=[peak_fitting_results[\"height\"]],\n                showlegend=False,\n                hovertext=\"\".join(hovertext),\n                text=annotation_text,\n                mode=\"markers+text\",\n                textposition=\"top center\",\n                name=name,\n                marker={\"color\": darken(color_palette[(instrument, wavelength_nm)])},\n            ),\n            row=subplot_row,\n            col=subplot_col,\n        )\n\n        # Plot fitted Voigt profile for each peak\n        x_data = np.linspace(peak_center - window_size, peak_center + window_size, 500)\n        model_params = [peak_fitting_results[p] for p in [\"amplitude\", \"center\", \"sigma\", \"gamma\"]]\n        y_data = model.func(x_data, *model_params)\n        fig.add_trace(\n            go.Scatter(\n                x=x_data,\n                y=y_data,\n                showlegend=False,\n                hoverinfo=\"skip\",\n                marker={\"color\": darken(color_palette[(instrument, wavelength_nm)])},\n            ),\n            row=subplot_row,\n            col=subplot_col,\n        )\n\n# Create pandas DataFrame of peak fitting results\nacetonitrile_peaks_dataframe = pd.DataFrame.from_records(peak_fitting_records).drop(\"gamma\", axis=1)\n\n# Configure plotly layout\nlayout = get_default_plotly_layout()\nfig.update_layout(layout, height=450)\nfig.update_xaxes(range=[wavenumber_range_cm1[0] - 100, wavenumber_range_cm1[1] + 100])\nfig.update_yaxes(range=[-0.05, 1.3])\nfig.update_xaxes(title_text=\"Wavenumber (cm&lt;sup&gt;-1&lt;/sup&gt;)\", row=num_rows, col=1)\nfig.update_xaxes(title_text=\"Wavenumber (cm&lt;sup&gt;-1&lt;/sup&gt;)\", row=num_rows, col=2)\nfig.update_yaxes(title_text=\"Intensity (normalized)\", row=2, col=1)\nfig.show()\n\n\n\n\n                                                \n\n\nFigure 1: Acetonitrile spectra from each instrument. The four most prominent peaks for each spectrum are detected and fit using a Voigt profile. Hovering the cursor over each peak lets you see the measured FWHM, height, and offset from the reference peak value.\n\n\n\n\nBy analyzing the same acetonitrile sample across instruments, we can control for sample-dependent variables, allowing us to make meaningful comparisons of the relative performance of each spectrometer based on full width at half maximum (FWHM)3 measurements. The reference peak at ~918 cm^-1 is comparatively isolated, so the FWHM won’t be impacted by other components of the spectrum. Let’s choose this peak to compare FWHM values, noting that the observed FWHM is influenced by both instrumental factors (e.g., quality of optical components) and sample characteristics (e.g., molecular dynamics and environmental conditions).\n3 While the FWHM serves as a useful indicator of spectral quality, it’s important to note that true spectral resolution is defined by the minimum separation at which two adjacent peaks can be distinguished rather than by individual peak widths alone.\nacetonitrile_peaks_dataframe.query(\"reference == 918\").set_index([\"instrument\", \"λ_nm\"]).round(1)\n\n\n\n\n\n\n\n  \n    \n      \n      \n      amplitude\n      center\n      sigma\n      fwhm\n      height\n      reference\n      offset\n    \n    \n      instrument\n      λ_nm\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      horiba\n      785\n      10.9\n      918.5\n      4.7\n      11.7\n      0.8\n      918\n      0.5\n    \n    \n      renishaw\n      785\n      6.2\n      921.8\n      3.2\n      8.2\n      0.7\n      918\n      3.8\n    \n    \n      wasatch\n      785\n      6.5\n      921.4\n      4.8\n      11.9\n      0.5\n      918\n      3.4\n    \n    \n      openraman\n      532\n      4.0\n      921.4\n      8.7\n      21.0\n      0.2\n      918\n      3.4\n    \n    \n      wasatch\n      532\n      1.9\n      927.1\n      5.9\n      14.5\n      0.1\n      918\n      9.1\n    \n  \n\n\n\n\n\nTable 1: Peak fitting results from acetonitrile spectra collected by each instrument.\n\n\n\n\nThe peak fitting results in Table 1 show that the Renishaw has the lowest FWHM of any instrument at 8.2 cm-1. The Horiba and the 785 nm Wasatch are close behind at 11.7 cm-1 and 11.9 cm-1, respectively. Additionally, we found that the Horiba is the best calibrated in this spectral range as it has the smallest offset in peak position from the reference. While spectral accuracy is important, we’re less concerned here, given that we can always recalibrate spectra as part of a post-processing workflow using reference materials. Furthermore, for most of our research, we’re more interested in relative differences among spectra than absolute differences.\nLet’s continue the comparison by exploring spectra from biological samples.\n\n\nCharacterizing SNR with C. reinhardtii spectra\nWe’re shifting our focus from a standard sample (acetonitrile) to biological samples, specifically unicellular algae, to determine how the different spectrometers perform for our experiments of interest. We collected Raman spectra of Chlamydomonas reinhardtii (CC-124)—a model organism we frequently use in the lab—from each instrument. Since biological samples introduce more complexity than pure compounds, we need to assess the signal-to-noise ratio (SNR) of these spectra to determine which instruments offer the highest sensitivity and are best suited for detecting subtle spectral features. This characterization will help us identify the most sensitive spectrometer for future experiments where detecting faint biochemical signals is critical. In addition to SNR measurements, we’ll make (relatively crude) peak-finding calculations to get a rough sense of the number of features we can resolve from each spectrum. We’ll use the find_peaks function from SciPy, which finds the local maxima in a 1D signal, and filter this set of local maxima to the peaks we’re interested in resolving by defining parameters such as the relative prominence and the distance between peaks.\nWe’ll also need to perform baseline subtraction to derive meaningful SNR measurements, as raw Raman spectra often contain fluorescence and other background signals that obscure meaningful peaks. In a separate analysis, we evaluated different baseline estimation algorithms. We found that adaptive smoothness penalized least squares (asPLS) performed the best at removing background while preserving key spectral features (Zhang et al., 2020). We use the implementation of asPLS in pybaselines with the smoothing parameter changed to lam = 1e4, as we found empirically that this value provided better baseline estimation for our dataset.\n\nfrom analysis.load_spectra import load_cc124_tap_spectra\nfrom pybaselines.whittaker import aspls\nfrom ramanalysis import RamanSpectrum\nfrom scipy.signal import find_peaks\n\ncc124_tap_spectra, cc124_tap_dataframe = load_cc124_tap_spectra()\n\n\n# Define a function for calculating peak SNR\ndef compute_peak_snr(\n    spectrum: RamanSpectrum,\n    noisy_region_cm1: tuple[float, float],\n) -&gt; float:\n    \"\"\"Peak SNR measurement.\"\"\"\n    noise = spectrum.normalize().between(*noisy_region_cm1).intensities.std()\n    peak_snr = 1 / noise\n    return peak_snr\n\n\n# Parameters for baseline subtraction\nlam = 1e4\nwavenumber_range_cm1 = (520, 3200)\n\n# Parameters for SNR calculation\nnoisy_region_cm1 = (1700, 2500)\n\n# Parameters for peak finding\nrelative_prominences = {\n    (\"horiba\", 785): 0.5,\n    (\"renishaw\", 785): 0.1,\n    (\"wasatch\", 785): 0.1,\n    (\"openraman\", 532): 0.5,\n    (\"wasatch\", 532): 0.1,\n}\npeak_separation = 10\n\nFigure 2 shows the peak SNR measurements of each instrument and the approximate number of peaks.\n\n\nSource code for this figure:\n# Store peak SNR measurement results\nsnr_measurements = []\n\n# Create figure\nnum_rows = cc124_tap_dataframe.groupby([\"λ_nm\"]).count()[\"instrument\"].max().item()\nnum_cols = cc124_tap_dataframe[\"λ_nm\"].nunique()\nfig = make_subplots(\n    rows=num_rows,\n    cols=num_cols,\n    shared_xaxes=True,\n    shared_yaxes=True,\n    horizontal_spacing=0.02,\n    vertical_spacing=0.05,\n    column_titles=[\"785 nm\", \"532 nm\"],\n)\n\n# Map each (instrument, wavelength) combo to a subplot\nsubplot_indices = {  # (instrument, λ_nm) -&gt; (col, row)\n    (\"horiba\", 785): (1, 1),\n    (\"renishaw\", 785): (1, 2),\n    (\"wasatch\", 785): (1, 3),\n    (\"openraman\", 532): (2, 2),\n    (\"wasatch\", 532): (2, 3),\n}\n\nfor i, dataframe_row in cc124_tap_dataframe.iterrows():\n    # Get the raw spectrum and the instrument and wavelength with which it was recorded\n    wavelength_nm = dataframe_row[\"λ_nm\"]\n    instrument = dataframe_row[\"instrument\"]\n    raw_spectrum = cc124_tap_spectra[i]\n    subplot_col, subplot_row = subplot_indices[(instrument, wavelength_nm)]\n\n    # Crop and normalize spectra for baseline estimation\n    normalized_spectrum = raw_spectrum.between(*wavenumber_range_cm1).normalize()\n    # Apply median filtering on OpenRAMAN data to filter out hot pixels from the detector\n    if instrument == \"openraman\":\n        normalized_spectrum = normalized_spectrum.smooth(kernel_size=3)\n\n    # Estimate and subtract baseline\n    baseline_estimate, _params = aspls(normalized_spectrum.intensities, lam=lam)\n    baseline_subtracted_intensities = normalized_spectrum.intensities - baseline_estimate\n    baseline_subtracted_spectrum = RamanSpectrum(\n        wavenumbers_cm1=normalized_spectrum.wavenumbers_cm1,\n        intensities=baseline_subtracted_intensities,\n    ).normalize()\n\n    # Crop out saturated region from Wasatch 532 nm spectrum\n    if (instrument == \"wasatch\") and (wavelength_nm == 532):\n        baseline_subtracted_spectrum = baseline_subtracted_spectrum.between(0, 1800).normalize()\n\n    # Calculate peak SNR\n    snr = compute_peak_snr(baseline_subtracted_spectrum, noisy_region_cm1)\n    snr_measurements.append(snr)\n\n    # Find prominent peaks\n    peaks, _peak_properties = find_peaks(\n        baseline_subtracted_spectrum.intensities,\n        relative_prominences[(instrument, wavelength_nm)],\n        distance=peak_separation,\n    )\n    peaks_cm1, peak_heights = baseline_subtracted_spectrum.interpolate(peaks)\n\n    # Plot each raw (normalized) spectrum\n    fig.add_trace(\n        go.Scatter(\n            x=normalized_spectrum.wavenumbers_cm1,\n            y=normalized_spectrum.intensities,\n            hoverinfo=\"skip\",\n            showlegend=False,\n            marker={\"color\": color_palette[(instrument, wavelength_nm)]},\n            opacity=0.5,\n        ),\n        row=subplot_row,\n        col=subplot_col,\n    )\n\n    # Plot each baseline estimate\n    fig.add_trace(\n        go.Scatter(\n            x=normalized_spectrum.wavenumbers_cm1,\n            y=baseline_estimate - 0.05,\n            hoverinfo=\"skip\",\n            showlegend=False,\n            marker={\"color\": darken(color_palette[(instrument, wavelength_nm)])},\n            opacity=0.5,\n        ),\n        row=subplot_row,\n        col=subplot_col,\n    )\n\n    # Plot baseline subtracted spectra\n    name = f\"{instrument.capitalize()}\"\n    fig.add_trace(\n        go.Scatter(\n            x=baseline_subtracted_spectrum.wavenumbers_cm1,\n            y=baseline_subtracted_spectrum.intensities,\n            name=name,\n            hoverinfo=\"skip\",\n            marker={\"color\": color_palette[(instrument, wavelength_nm)]},\n        ),\n        row=subplot_row,\n        col=subplot_col,\n    )\n\n    # Plot peaks\n    fig.add_trace(\n        go.Scatter(\n            x=peaks_cm1,\n            y=peak_heights,\n            name=name,\n            mode=\"markers\",\n            marker={\"color\": color_palette[(instrument, wavelength_nm)]},\n            showlegend=False,\n        ),\n        row=subplot_row,\n        col=subplot_col,\n    )\n\n    # Plot SNR and num peaks annotation\n    text = f\"Peak SNR: {snr:.1f}&lt;br&gt;Num peaks: {peaks.size:.0f}\"\n    fig.add_trace(\n        go.Scatter(\n            x=[2000],\n            y=[0.6],\n            showlegend=False,\n            text=text,\n            mode=\"text\",\n            textposition=\"middle right\",\n            name=name,\n        ),\n        row=subplot_row,\n        col=subplot_col,\n    )\n\n# Create pandas DataFrame of peak fitting results\ncc124_tap_dataframe[\"snr\"] = snr_measurements\n\n# Configure plotly layout\nfig.update_layout(layout, height=450)\nfig.update_xaxes(range=[wavenumber_range_cm1[0] - 100, wavenumber_range_cm1[1] + 100])\nfig.update_yaxes(range=[-0.05, 1.3])\nfig.update_xaxes(title_text=\"Wavenumber (cm&lt;sup&gt;-1&lt;/sup&gt;)\", row=num_rows, col=1)\nfig.update_xaxes(title_text=\"Wavenumber (cm&lt;sup&gt;-1&lt;/sup&gt;)\", row=num_rows, col=2)\nfig.update_yaxes(title_text=\"Intensity (normalized)\", row=2, col=1)\nfig.show()\n\n\n\n\n                                                \n\n\nFigure 2: Peak SNR measurements and detected peaks in C. reinhardtii spectra from each instrument. Each subplot shows the baseline-subtracted spectrum on which the peak SNR measurements are made. Behind the baseline-subtracted spectra, the raw C. reinhardtii spectra and estimated baselines are shown with semi-transparency. Note that the estimated baselines are slightly recessed from the raw spectra for visualization. Clicking on the instrument name in the legend toggles the display of the baseline-subtracted spectra to view the raw spectrum and estimated baseline more easily.\n\n\n\n\nThese measurements indicate that the Renishaw and 785 nm Wasatch systems provide the highest peak SNR values. The OpenRAMAN exhibits the lowest SNR, which aligns with expectations given its relatively low-cost components. In particular, the OpenRAMAN has by far the weakest laser power of any system and likely the most read noise from the detector; in contrast to the other systems, the camera is not cooled. Perhaps not surprisingly, the two instruments with the highest SNR also have the highest number of discernible spectral features.\nThe excitation wavelength greatly affects the usable signal. While it also has a relatively high SNR, the number of features in the 532 nm Wasatch spectrum is much lower. This suggests that 532 nm may be less optimal for analyzing these particular types of samples. It should be noted that the number of peaks detected in each spectrum is only an approximation.\nNow, we’ll move on to applications requiring large spectral datasets, such as batch processing and machine learning (ML) techniques. These approaches will help us evaluate the reproducibility of each instrument and assess their sensitivity to subtle variations in, e.g., differentiating strains and growth conditions of our cell samples.\n\n\nBatch preprocessing of Chlamydomonas spectra\nThe C. reinhardtii spectra characterized above come from a much larger dataset of Chlamydomonas spectra. Three strains of Chlamydomonas, representing two species, were cultured in two different media conditions, as described in Section 3. With each instrument, we acquired Raman spectra from plates (or, in the case of the Renishaw, glass slides) of cells representing each of these six treatments.\nLet’s load the full dataset of spectra and associated metadata—a random sample of metadata from ten spectra from this dataset is shown in Table 2.\n\nfrom analysis.load_spectra import load_chlamy_spectra\n\n# Load all the spectra of Chlamydomonas and the corresponding metadata\nchlamy_spectra, chlamy_dataframe = load_chlamy_spectra()\n\n# Show a sample of spectra metadata\nprint(f\"Total number of Chlamydomonas spectra: {len(chlamy_dataframe)}\")\nchlamy_dataframe.sample(10, random_state=57).reset_index(drop=True)\n\nTotal number of Chlamydomonas spectra: 536\n\n\n\n\n\n\n\n\n  \n    \n      \n      instrument\n      λ_nm\n      species\n      strain\n      medium\n    \n  \n  \n    \n      0\n      renishaw\n      785\n      C. reinhardtii\n      CC-124\n      TAP\n    \n    \n      1\n      renishaw\n      785\n      C. reinhardtii\n      CC-125\n      TAP\n    \n    \n      2\n      wasatch\n      532\n      C. smithii\n      CC-1373\n      TAP\n    \n    \n      3\n      openraman\n      532\n      C. reinhardtii\n      CC-125\n      TAP\n    \n    \n      4\n      openraman\n      532\n      C. smithii\n      CC-1373\n      M-N\n    \n    \n      5\n      wasatch\n      532\n      C. smithii\n      CC-1373\n      TAP\n    \n    \n      6\n      wasatch\n      785\n      C. reinhardtii\n      CC-125\n      M-N\n    \n    \n      7\n      wasatch\n      785\n      C. reinhardtii\n      CC-124\n      M-N\n    \n    \n      8\n      openraman\n      532\n      C. reinhardtii\n      CC-125\n      M-N\n    \n    \n      9\n      wasatch\n      785\n      C. reinhardtii\n      CC-125\n      M-N\n    \n  \n\n\n\n\n\nTable 2: Metadata corresponding to a random sample of ten spectra from the Chlamydomonas dataset comprised of spectra from each instrument.\n\n\n\n\nSince these spectra capture biochemical variations between species and environmental influences, we aim to apply machine-learning techniques to distinguish between groups. However, before diving into the modeling, we need to perform batch preprocessing to correct for background fluorescence, noise from the detectors, and other experimental inconsistencies. This ensures that our spectral differences reflect biological variability (as much as possible) rather than artifacts from acquisition conditions, improving the reliability of our classification models. The preprocessing pipeline is comprised of the following steps:\n\nDenoising: Smooth spectra with Savitzky-Golay filter.\nCropping: Crop spectra to the region of interest (300–1,800 cm-1).\nBaseline subtraction: Fit and remove the fluorescence baseline using the asPLS algorithm.\nNormalization: Apply min-max normalization to scale the spectra for consistency across samples.\n\nBecause data acquired with the Renishaw instrument was collected from glass slides, we need to perform an additional background subtraction. Glass has a distinct Raman spectrum that overlaps with spectral regions of interest from our biological samples (Fikiet et al., 2020), requiring a separate correction to prevent it from confounding our analysis. Figure 3 shows the results of our preprocessing pipeline on the Chlamydomonas dataset.\n\n\n\n\n\n\nNote\n\n\n\nWhen we collected data on the Horiba instrument, our focus wasn’t on ML classification tasks, so we didn’t design the dataset with that goal in mind. As a result, we don’t have a sufficient number of samples to support meaningful classification analysis. Given these limitations, we excluded this dataset from our classification efforts.\n\n\n\n\nSource code for this figure and the preprocessing pipeline:\nfrom scipy.signal import savgol_filter\n\n# Preprocessing parameters\nsavgol_window_length = 9\nsavgol_polynomial_order = 3\nfingerprint_region_cm1 = (300, 1800)\n\n# Load spectrum from Renishaw glass slide control\ntxt_filepath = \"data/Renishaw_Qontor/glass_slide_background.txt\"\nglass_slide_control_spectrum = RamanSpectrum.from_renishaw_txtfile(txt_filepath)\n\n# Store preprocessed spectra\npreprocessed_chlamy_spectra = []\n\nfor i, dataframe_row in chlamy_dataframe.iterrows():\n    # Get the raw spectrum and its associated metadata\n    raw_spectrum = chlamy_spectra[i]\n    wavelength_nm = dataframe_row[\"λ_nm\"]\n    instrument = dataframe_row[\"instrument\"]\n    strain = dataframe_row[\"strain\"]\n    medium = dataframe_row[\"medium\"]\n\n    # Preprocessing steps\n    # -------------------\n    # 0.5) Apply median filtering on OpenRAMAN data to filter out hot pixels from the detector\n    if instrument == \"openraman\":\n        raw_spectrum = raw_spectrum.smooth(kernel_size=3)\n    # 1) Denoising\n    smoothed_intensities = savgol_filter(\n        raw_spectrum.intensities,\n        window_length=savgol_window_length,\n        polyorder=savgol_polynomial_order,\n    )\n    # 1.5) Glass slide background subtraction for the Renishaw\n    if instrument == \"renishaw\":\n        smoothed_intensities -= glass_slide_control_spectrum.intensities\n    # 2) Crop spectral range to the fingerprint region\n    cropped_spectrum = RamanSpectrum(\n        wavenumbers_cm1=raw_spectrum.wavenumbers_cm1,\n        intensities=smoothed_intensities,\n    ).between(*fingerprint_region_cm1)\n    # 2.5) Additional cropping for 532 nm Wasatch\n    if (instrument == \"wasatch\") and (wavelength_nm == 532):\n        cropped_spectrum = cropped_spectrum.between(0, 1700)\n    # 3) Baseline subtraction\n    baseline_estimate, _params = aspls(cropped_spectrum.intensities, lam=lam)\n    baseline_subtracted_intensities = cropped_spectrum.intensities - baseline_estimate\n    # 4) Compose into RamanSpectrum and normalize\n    preprocessed_spectrum = RamanSpectrum(\n        wavenumbers_cm1=cropped_spectrum.wavenumbers_cm1,\n        intensities=baseline_subtracted_intensities,\n    ).normalize()\n    preprocessed_chlamy_spectra.append(preprocessed_spectrum)\n\n# Create figure\nnum_rows = len(chlamy_dataframe.groupby([\"instrument\", \"λ_nm\"]).nunique()) + 1\nnum_cols = 2\nfig = make_subplots(\n    rows=num_rows,\n    cols=num_cols,\n    row_heights=[0.5, 0.5, 0.1, 0.5, 0.5],  # add space to separate 532 vs 785 subplots\n    shared_xaxes=True,\n    shared_yaxes=True,\n    horizontal_spacing=0.02,\n    vertical_spacing=0.05,\n    column_titles=[\"Raw\", \"Preprocessed\"],\n)\n# Map each (instrument, wavelength) combo to a subplot\nsubplot_rows = {  # (instrument, λ_nm) -&gt; row\n    (\"renishaw\", 785): 1,\n    (\"wasatch\", 785): 2,\n    (\"openraman\", 532): 4,\n    (\"wasatch\", 532): 5,\n}\n\nfor (instrument, wavelength_nm), dataframe_group in chlamy_dataframe.groupby(\n    [\"instrument\", \"λ_nm\"]\n):\n    # Only show a sample of spectra to avoid rendering issues\n    num_samples = min(50, len(dataframe_group))\n    for i, dataframe_row in dataframe_group.sample(num_samples).iterrows():\n        # Get the raw and preprocessed spectra and its associated metadata\n        raw_spectrum = chlamy_spectra[i]\n        preprocessed_spectrum = preprocessed_chlamy_spectra[i]\n        strain = dataframe_row[\"strain\"]\n        medium = dataframe_row[\"medium\"]\n        subplot_row = subplot_rows[(instrument, wavelength_nm)]\n\n        # Plot each raw spectrum\n        fig.add_trace(\n            go.Scatter(\n                x=raw_spectrum.wavenumbers_cm1,\n                y=raw_spectrum.normalize().intensities,\n                hoverinfo=\"skip\",\n                legendgroup=strain + medium,\n                showlegend=False,\n                marker={\"color\": color_palette[(strain, medium)]},\n                opacity=0.5,\n            ),\n            row=subplot_row,\n            col=1,\n        )\n\n        # Plot each preprocessed spectrum\n        fig.add_trace(\n            go.Scatter(\n                x=preprocessed_spectrum.wavenumbers_cm1,\n                y=preprocessed_spectrum.intensities,\n                hoverinfo=\"skip\",\n                legendgroup=strain + medium,\n                showlegend=False,\n                marker={\"color\": color_palette[(strain, medium)]},\n                opacity=0.5,\n            ),\n            row=subplot_row,\n            col=2,\n        )\n\n# Plot fake traces for legend\nordered_groups = [\n    (\"CC-124\", \"TAP\"),\n    (\"CC-125\", \"TAP\"),\n    (\"CC-1373\", \"TAP\"),\n    (\"CC-124\", \"M-N\"),\n    (\"CC-125\", \"M-N\"),\n    (\"CC-1373\", \"M-N\"),\n]\nfor strain, medium in ordered_groups:\n    fig.add_trace(\n        go.Scatter(\n            x=[None],\n            y=[None],\n            mode=\"lines\",\n            name=f\"{strain} | {medium}\",\n            line={\"color\": color_palette[(strain, medium)], \"width\": 3},\n            legendgroup=strain + medium,\n            showlegend=True,\n        )\n    )\n\n# Configure plotly layout\nfig.update_layout(layout, height=600)\nfig.update_xaxes(title_text=\"Wavenumber (cm&lt;sup&gt;-1&lt;/sup&gt;)\", row=num_rows, col=1)\nfig.update_xaxes(title_text=\"Wavenumber (cm&lt;sup&gt;-1&lt;/sup&gt;)\", row=num_rows, col=2)\nfor (instrument, wavelength_nm), row in subplot_rows.items():\n    title = f\"{instrument.capitalize()}&lt;br&gt;{wavelength_nm} nm\"\n    fig.update_yaxes(title_text=title, row=row, col=1)\nfig.show()\n\n\n\n\n                                                \n\n\nFigure 3: Raw (left) and preprocessed (right) spectra from Chlamydomonas samples. Each row of subplots shows the spectra from a different instrument. Spectra from TAP-grown cells are shown in shades of blue; spectra from nitrogen-depleted cells are shown in shades of red. You can double-click on a particular strain, medium combination in the legend to isolate it. At most, 50 spectra from each group are shown to prevent rendering issues.\n\n\n\n\nOur preprocessing pipeline worked well for the raw spectra, even though the instruments and excitation wavelengths vary greatly. For example, the fluorescence background for the 532 nm and 785 nm excitations had very different shapes but were managed well by the baseline subtraction we applied. As expected, the most significant factor driving spectral differences was the excitation wavelength, followed by which instrument we used. After controlling for these technical variables, the remaining differences in our processed spectra should mainly reveal the unique biochemical fingerprints of each algal strain and how they responded to different growth conditions.\nThe 532 nm spectra match well with peaks reported in some of the literature for C. reinhardtii CC-125, showing three major peaks ~1006, ~1156, and ~1520 cm-1 that have been ascribed to carotenoid pigments (Pandey et al., 2022). The 785 nm spectra generally match those from additional literature on Chlamydomonas (Samek et al., 2010), and we think a majority of the peaks are due to vibrational modes of pigments, based on studies with similarly pigmented species (Ishihara and Takahashi, 2023). Finally, we noticed that cells cultured in nitrogen-depleted media don’t have the expected lipid peaks as seen in other research studying Raman-detectable responses of other algae to nitrogen depletion (He et al., 2012). This change is also expected in C. reinhardtii (CC-125) (Msanne et al., 2012). None of our spectra had strong peaks in the 2800–3000 cm-1 C-H stretch region, where lipid peaks are prominent, contrasting to the literature on other strains of Chlamydomonas (Sharma et al., 2015). The absence of these peaks may be attributed to insufficient nitrogen depletion conditions in our cultures, though further investigation is required to know for sure.\n\n\nLinear discriminant analysis of Chlamydomonas spectra\nNow that we have preprocessed the Raman spectra from each instrument, we can apply linear discriminant analysis (LDA) to explore how the spectra cluster based on strain differences and growth media (Figure 4). This analysis will help us identify the spectral features that best separate these groups, providing insight into how well Raman spectra can distinguish between strains and media compositions. We’ll first conduct principal component analysis (PCA) as a preprocessing step for LDA to denoise the data, reduce dimensionality, and remove multicollinearity between features. We’ve selected ten principal components, which collectively explain approximately 80% of the total variance in our dataset. We saw clear signs of overfitting when testing with a higher number of components.\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n# Set number of PCA and LDA components\nnum_pca_components = 10\nnum_lda_components = 2\n\n# Define groups and group labels\ngroup_labels = {\n    (\"CC-124\", \"M-N\"): 0,\n    (\"CC-125\", \"M-N\"): 1,\n    (\"CC-1373\", \"M-N\"): 2,\n    (\"CC-124\", \"TAP\"): 3,\n    (\"CC-125\", \"TAP\"): 4,\n    (\"CC-1373\", \"TAP\"): 5,\n}\n\n\n\nSource code for this figure and the LDA:\nimport plotly.express as px\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nordered_groups = [\n    (\"renishaw\", 785),\n    (\"wasatch\", 785),\n    (\"wasatch\", 532),\n    (\"openraman\", 532),\n]\n\nfor instrument, wavelength_nm in ordered_groups:\n    # Filter DataFrame for instrument and excitation wavelength\n    grp = chlamy_dataframe.query(\"instrument == @instrument & λ_nm == @wavelength_nm\")\n\n    # Compose training data\n    X = []\n    y = []\n    for (_strain, _medium), label in group_labels.items():\n        indices_in_group = grp.query(\"strain == @_strain & medium == @_medium\").index.values\n        spectra_in_group = [preprocessed_chlamy_spectra[i] for i in indices_in_group]\n        for spectrum in spectra_in_group:\n            X.append(spectrum.intensities)\n            y.append(label)\n    X = np.array(X)\n    y = np.array(y)\n\n    # Construct LDA pipeline\n    pipeline = Pipeline(\n        [\n            (\"scaler\", StandardScaler()),\n            (\"pca\", PCA(n_components=num_pca_components, random_state=42)),\n            (\"lda\", LinearDiscriminantAnalysis(n_components=num_lda_components, solver=\"svd\")),\n        ]\n    )\n    # Fit and transform LDA\n    spectral_components = pipeline.fit(X, y).transform(X)\n    # Extract explained variance ratios\n    _pca_variances = pipeline.named_steps[\"pca\"].explained_variance_ratio_\n    lda_variances = pipeline.named_steps[\"lda\"].explained_variance_ratio_\n\n    # Add LDA components to DataFrame for plotting\n    source = pd.DataFrame(\n        {\n            \"LD-1\": spectral_components[:, 0],\n            \"LD-2\": spectral_components[:, 1],\n            \"label\": y,\n        }\n    )\n    group_labels_inverted = {k: v for v, k in group_labels.items()}\n    source[\"Group\"] = source[\"label\"].map(group_labels_inverted)\n\n    # LDA plots\n    fig = px.scatter(\n        source,\n        x=\"LD-1\",\n        y=\"LD-2\",\n        color=\"Group\",\n        color_discrete_map=color_palette,\n        marginal_x=\"box\",\n        marginal_y=\"box\",\n    )\n\n    # Configure plotly layout\n    fig.update_layout(\n        layout,\n        title=f\"{instrument.capitalize()} | {wavelength_nm} nm\",\n        xaxis_title=f\"LD-1 ({lda_variances[0]:.1%})\",\n        yaxis_title=f\"LD-2 ({lda_variances[1]:.1%})\",\n        height=500,\n        width=600,\n        xaxis={\"scaleanchor\": \"y\"},\n    )\n    fig.show()\n\n\n\n\n\n\n\n                                                \n\n\n(a) LDA of Chlamydomonas spectra from the Renishaw (785 nm).\n\n\n\n\n\n\n                                                \n\n\n(b) LDA of Chlamydomonas spectra from the Wasatch (785 nm).\n\n\n\n\n\n\n                                                \n\n\n(c) LDA of Chlamydomonas spectra from the Wasatch (532 nm).\n\n\n\n\n\n\n                                                \n\n\n(d) LDA of Chlamydomonas spectra from the OpenRAMAN (532 nm).\n\n\n\n\n\nFigure 4: Linear discriminant analysis (LDA) of Chlamydomonas spectra.\n\n\n\n\nAlthough the LDA results exhibit substantial variance across instruments, a consistent pattern emerges in which one of the linear discriminants differentiates spectra based on growth media. This is evident in the data from the 785 nm instruments (Figure 4a–b) in which spectra from M-N cultures predominantly cluster above the spectra from TAP-grown cells (LD-2). Interestingly, the 785 nm Wasatch data also show evidence of species-level differentiation along LD-1. While there doesn’t appear to be a clear separation between strains or species in the spectra from the 532 nm instruments (Figure 4c–d), we do see variation from growth media in the 532 nm Wasatch (LD-1). Despite the OpenRAMAN and 532 nm Wasatch having the same excitation wavelengths, we were able to extract more spectral features from the Wasatch system (Figure 2), which may account for the differences in clustering between these two systems.\n\n\nSpecies classification\nGiven that we see some species-level variation in the LDA, let’s determine how accurately we can classify each species using different machine-learning (ML) classifiers. We’ll implement and compare a few classification algorithms we expect to perform reasonably well for this task: random forest, logistic regression, and linear discriminant analysis (already tested qualitatively). We’ll include a dummy classifier as a control to validate that the models outperform random guessing. For a more reliable performance estimate, we’ll employ stratified k-fold cross-validation (with k = 5), which preserves the class distribution in each fold, ensuring our test results better reflect how these models would perform on new, unseen spectra. The results of our species classification task are shown in Figure 5.\n\nfrom analysis.classification import BatchClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm.notebook import tqdm\n\nclassifiers = [\n    RandomForestClassifier,\n    LogisticRegression,\n    LinearDiscriminantAnalysis,\n    DummyClassifier,\n]\nspecies_labels = {\n    \"C. reinhardtii\": 0,\n    \"C. smithii\": 1,\n}\nnum_splits = 5\n\nclassification_results_dataframe = pd.DataFrame()\nfor (instrument, wavelength_nm), grp in chlamy_dataframe.groupby([\"instrument\", \"λ_nm\"]):\n    # Compose training data\n    X = []\n    y = []\n    for _species, label in species_labels.items():\n        indices_in_group = grp.query(\"species == @_species\").index.values\n        spectra_in_group = [preprocessed_chlamy_spectra[i] for i in indices_in_group]\n        for spectrum in spectra_in_group:\n            X.append(spectrum.intensities)\n            y.append(label)\n    X = np.array(X)\n    y = np.array(y)\n\n    # Initialize K-folds cross-validation and batch classifier\n    kfolds = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=37)\n    batch_classifier = BatchClassifier(classifiers=classifiers, random_state=37)\n\n    # Train classifiers and predict\n    for train, test in tqdm(kfolds.split(X, y), total=num_splits):\n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n        scores = batch_classifier.fit(X_train, X_test, y_train, y_test).reset_index()\n        scores[\"instrument\"] = instrument\n        scores[\"wavelength_nm\"] = wavelength_nm\n        classification_results_dataframe = pd.concat([scores, classification_results_dataframe])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource code for this figure:\n# Map each (instrument, wavelength) combo to a subplot\nsubplot_rows = {  # (instrument, λ_nm) -&gt; row\n    (\"renishaw\", 785): 1,\n    (\"wasatch\", 785): 2,\n    (\"openraman\", 532): 3,\n    (\"wasatch\", 532): 4,\n}\nsubplot_titles = [f\"{k[0].capitalize()} | {k[1]} nm\" for k in subplot_rows.keys()]\n\n# Create figure\nnum_rows = len(chlamy_dataframe.groupby([\"instrument\", \"λ_nm\"]).nunique())\nfig = make_subplots(\n    rows=num_rows,\n    cols=1,\n    shared_xaxes=True,\n    subplot_titles=subplot_titles,\n)\n\nclassification_results_dataframe = classification_results_dataframe.reset_index(drop=True)\nfor (instrument, wavelength_nm), scores in classification_results_dataframe.groupby(\n    [\"instrument\", \"wavelength_nm\"]\n):\n    # Aggregate mean + std from each k-fold\n    # (unfortunately plotly can't automatically do this from long-form DataFrames like seaborn)\n    source = scores.groupby(\"model\")[\"balanced_accuracy\"].agg([\"mean\", \"std\"]).reset_index()\n    subplot_row = subplot_rows[(instrument, wavelength_nm)]\n\n    # Create bar plot to show classification accuracy for each instrument\n    fig.add_trace(\n        go.Bar(\n            y=source[\"model\"],\n            x=source[\"mean\"],\n            showlegend=False,\n            error_x={\"array\": source[\"std\"]},\n            marker={\"color\": color_palette[(instrument, wavelength_nm)]},\n            orientation=\"h\",\n        ),\n        row=subplot_row,\n        col=1,\n    )\n\n# Configure plotly layout\nfig.update_layout(layout, height=650)\nfig.update_xaxes(title_text=\"Balanced accuracy\", row=num_rows, tickformat=\".0%\")\nfig.show()\n\n\n\n\n                                                \n\n\nFigure 5: Species classification of Chlamydomonas spectra. Error bars indicate the standard deviation in the balanced accuracy of the k = 5 folds.\n\n\n\n\nOverall, the classifiers were fairly accurate in differentiating Chlamydomonas species based on spectral data. Importantly, all instruments produced spectra that yielded above-random classification performance. The 785 nm Wasatch achieved the highest classification accuracy (97%) using logistic regression, consistent with its highest-ranking clustering in the LDA analysis. Interestingly, the OpenRAMAN outperformed the 532 nm Wasatch, possibly due to its effectiveness in distinguishing C. smithii grown in M-N media, which appeared distinctly separated in its LDA projection (Figure 4b). Model selection didn’t heavily impact outcomes, though logistic regression generally showed slight advantages across instruments—only for the OpenRAMAN did random forest classification surpass it."
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "Comparison of spontaneous Raman spectrometers –",
    "section": "Discussion",
    "text": "Discussion\nRecall that our objective wasn’t to establish which spectrometer was “best” but rather to determine which instrument(s) and acquisition parameters (particularly excitation wavelength) best aligned with our specific applications and budget. The Wasatch systems emerged as particularly well-suited to our needs, demonstrating excellent SNR characteristics, revealing numerous spectral features (especially at 785 nm), producing effective clustering in LDA, and showing superior species differentiation capabilities. The results of the multidimensional analysis are clearly sensitive to the choice of instrument and acquisition parameters, as evidenced by clustering patterns varying substantially between different instruments. This dependence highlights the importance of implementing appropriate controls and orthogonal analysis methods to validate LDA-derived results prior to drawing biological conclusions.\nBeyond these performance metrics, there are a number of important considerations not captured in our analysis. Chief among them were ease of operation and automation potential—critical factors for high-throughput data collection. In this regard, the Wasatch systems also excelled, with their open-source software framework facilitating the efficient collection of large spectral datasets. We also didn’t evaluate the spectrometers’ spatial characteristics (e.g., spot size, depth of field) as these parameters were less important for our applications, and not all instruments had imaging capabilities. Had this been a greater priority, we might have leaned more towards the Renishaw, as this system demonstrated superior performance in this area. Our experiments demonstrated, however, that a probe-based Raman spectroscopy system is sufficient for a wide range of biological applications. Although cost was another factor we considered, we chose to focus the scope of this work purely on the analytical components.\nOur secondary objective was to showcase a range of analytical techniques, particularly well-suited to Raman spectral datasets, and to present them in an interactive and easily reproducible format. We’ve demonstrated various approaches—from basic preprocessing to dimensionality reduction and classification methods—that can extract meaningful biological information from spectral data. We hope these techniques and the open-source package that facilitated some of the analysis, ramanalysis, prove valuable to other researchers and perhaps inspire new analytical strategies in their own work. This analysis reflects our belief that Raman spectroscopy, despite its powerful capabilities for non-destructive molecular profiling, remains underutilized as a tool for phenotyping in biological research."
  },
  {
    "objectID": "pages/SETUP.html",
    "href": "pages/SETUP.html",
    "title": "Setup",
    "section": "",
    "text": "This document details how to create a local copy of this pub’s codebase, setup your compute environment, and reproduce the pub itself. This will enable you to experiment with the analysis in the pub and, optionally, contribute revisions to it.\n\n\nThe codebase is hosted on GitHub and can be found here.\nTo obtain a local copy of this repo, you can either clone it directly or fork it to your own GitHub account, then clone your fork. If you aren’t sure what’s best, our suggestion is to clone directly unless you both (1) want to propose a revision for the publication and (2) are not an employee of Arcadia Science.\nTo clone:\ngit clone https://github.com/Arcadia-Science/2025-raman-spectrometer-comparison.git\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe publication is rendered with Quarto. If you don’t have it installed (check with quarto --version), you can install it here.\n\n\nThis repository uses conda to manage the computational and build environment. If you don’t have it installed (check with conda --version), you can find operating system-specific instructions for installing miniconda here. After installing, run the following commands to create and activate the environment.\nconda env create -n 2025-raman-spectrometer-comparison --file env.yml\nconda activate 2025-raman-spectrometer-comparison\nNow, install any internal packages in the repository:\npip install -e .\nAnd finally, if you plan to submit a pull request, install the pre-commit hooks:\npre-commit install"
  },
  {
    "objectID": "pages/SETUP.html#obtain-local-copy",
    "href": "pages/SETUP.html#obtain-local-copy",
    "title": "Setup",
    "section": "",
    "text": "The codebase is hosted on GitHub and can be found here.\nTo obtain a local copy of this repo, you can either clone it directly or fork it to your own GitHub account, then clone your fork. If you aren’t sure what’s best, our suggestion is to clone directly unless you both (1) want to propose a revision for the publication and (2) are not an employee of Arcadia Science.\nTo clone:\ngit clone https://github.com/Arcadia-Science/2025-raman-spectrometer-comparison.git"
  },
  {
    "objectID": "pages/SETUP.html#installation",
    "href": "pages/SETUP.html#installation",
    "title": "Setup",
    "section": "",
    "text": "Important\n\n\n\nThe publication is rendered with Quarto. If you don’t have it installed (check with quarto --version), you can install it here.\n\n\nThis repository uses conda to manage the computational and build environment. If you don’t have it installed (check with conda --version), you can find operating system-specific instructions for installing miniconda here. After installing, run the following commands to create and activate the environment.\nconda env create -n 2025-raman-spectrometer-comparison --file env.yml\nconda activate 2025-raman-spectrometer-comparison\nNow, install any internal packages in the repository:\npip install -e .\nAnd finally, if you plan to submit a pull request, install the pre-commit hooks:\npre-commit install"
  },
  {
    "objectID": "pages/SETUP.html#reproduce",
    "href": "pages/SETUP.html#reproduce",
    "title": "Setup",
    "section": "Reproduce",
    "text": "Reproduce\nThe best way to ensure you’ve correctly set up your code and compute environment is to reproduce this work. Fortunately, the analysis, and therefore the publication itself, can be reproduced with the following command:\nmake execute\n(Make sure you’re in the conda environment you created above)\nThis will execute and render the notebook index.ipynb, then build the publication site HTML, generating the directory _site/. Open _site/index.html to view your local copy of the publication."
  },
  {
    "objectID": "pages/SETUP.html#modify",
    "href": "pages/SETUP.html#modify",
    "title": "Setup",
    "section": "Modify",
    "text": "Modify\nTo modify or extend any analyses, open up index.ipynb with Jupyter or your favorite IDE:\njupyter-lab index.ipynb"
  },
  {
    "objectID": "pages/SETUP.html#preview",
    "href": "pages/SETUP.html#preview",
    "title": "Setup",
    "section": "Preview",
    "text": "Preview\nTo create a live preview of your pub, run the following:\nmake preview\nThis will open a local copy of the publication in your default browser. The command watches for changes such that whenever index.ipynb is saved, the publication is re-rendered."
  },
  {
    "objectID": "pages/SETUP.html#publish",
    "href": "pages/SETUP.html#publish",
    "title": "Setup",
    "section": "Publish",
    "text": "Publish\nIf you’ve improved the publication, consider contributing so we can update the hosted publication with your edits (big or small!). To get started, see our contributing guide."
  },
  {
    "objectID": "pages/CONTRIBUTING.html",
    "href": "pages/CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "We welcome improvements to this publication! If you’d like to improve or extend the publication, please submit a pull request. We’ll collaborate with you to incorporate your revisions. Alternatively, you’re welcome to leave a comment on the pub using Giscus.\n\nDid you spot any mistakes?\nDo you think an analysis is missing?\nDo you think the wording could be improved?\nDid you spot a typo or grammatical mistake?\n\nThese are just a few examples of revisions that we’d be happy to receive from you.\n\n\n\n\n\n\nNote\n\n\n\nTo learn about how we credit external collaborators, click here.\n\n\n\n\nIf you haven’t already, follow our setup guide to create a local copy of the code and compute environment.\n\n\n\nEdit index.ipynb to your liking.\n\n\n\nTo publish your revisions, we need you to open a pull request. And in order for us to merge your pull request, here’s what we’ll need from you in addition to your content changes.\nBegin with a clean branch (no uncommitted changes). Then run the notebook from the command line:\nmake execute\nThis command will update index.ipynb with the latest execution results.\nThen run make preview to see how the publication is rendering. Verify that your changes appear how you intend them to appear. If not, make the necessary changes and re-run make execute.\nOnce everything looks good, commit index.ipynb and all files in the _freeze/ directory.\nFinally, submit a pull request and we’ll work with you to merge your changes.\nOnce we approve and merge your pull request, we’ll publish a new version of the pub. We’ll notify you when this new version goes live at the hosted URL. Thanks for contributing!"
  },
  {
    "objectID": "pages/CONTRIBUTING.html#getting-started",
    "href": "pages/CONTRIBUTING.html#getting-started",
    "title": "Contributing",
    "section": "",
    "text": "If you haven’t already, follow our setup guide to create a local copy of the code and compute environment."
  },
  {
    "objectID": "pages/CONTRIBUTING.html#make-your-changes",
    "href": "pages/CONTRIBUTING.html#make-your-changes",
    "title": "Contributing",
    "section": "",
    "text": "Edit index.ipynb to your liking."
  },
  {
    "objectID": "pages/CONTRIBUTING.html#steps-before-publishing",
    "href": "pages/CONTRIBUTING.html#steps-before-publishing",
    "title": "Contributing",
    "section": "",
    "text": "To publish your revisions, we need you to open a pull request. And in order for us to merge your pull request, here’s what we’ll need from you in addition to your content changes.\nBegin with a clean branch (no uncommitted changes). Then run the notebook from the command line:\nmake execute\nThis command will update index.ipynb with the latest execution results.\nThen run make preview to see how the publication is rendering. Verify that your changes appear how you intend them to appear. If not, make the necessary changes and re-run make execute.\nOnce everything looks good, commit index.ipynb and all files in the _freeze/ directory.\nFinally, submit a pull request and we’ll work with you to merge your changes.\nOnce we approve and merge your pull request, we’ll publish a new version of the pub. We’ll notify you when this new version goes live at the hosted URL. Thanks for contributing!"
  },
  {
    "objectID": "pages/FAQ.html",
    "href": "pages/FAQ.html",
    "title": "FAQ",
    "section": "",
    "text": "This notebook publication uses a format we’re experimenting with that treats a scientist’s working computational analysis as the publication itself, dissolving the separation that exists between code and publication. Our hypothesis is that this lets us publish faster, promote early-stage work, and increase reproducibility. For details, see our commentary on notebook publications.\n\n\n\nThere is a comment section at the bottom of the pub, where you can read and contribute to any community discussion. Note that commenting requires a GitHub account and authorizing Giscus, a GitHub Discussions widget.\n\n\n\nAll the code for this publication and its analysis are hosted on GitHub at this URL. Any associated data is either hosted or linked to from this repository.\n\n\n\nReproducing this publication is as easy as issuing a few commands from the command line. Follow this setup guide to get started.\n\n\n\nWe welcome improvements to this publication! Please see our guide for contributing."
  },
  {
    "objectID": "pages/FAQ.html#what-is-this",
    "href": "pages/FAQ.html#what-is-this",
    "title": "FAQ",
    "section": "",
    "text": "This notebook publication uses a format we’re experimenting with that treats a scientist’s working computational analysis as the publication itself, dissolving the separation that exists between code and publication. Our hypothesis is that this lets us publish faster, promote early-stage work, and increase reproducibility. For details, see our commentary on notebook publications."
  },
  {
    "objectID": "pages/FAQ.html#how-can-i-comment",
    "href": "pages/FAQ.html#how-can-i-comment",
    "title": "FAQ",
    "section": "",
    "text": "There is a comment section at the bottom of the pub, where you can read and contribute to any community discussion. Note that commenting requires a GitHub account and authorizing Giscus, a GitHub Discussions widget."
  },
  {
    "objectID": "pages/FAQ.html#where-is-the-datacode",
    "href": "pages/FAQ.html#where-is-the-datacode",
    "title": "FAQ",
    "section": "",
    "text": "All the code for this publication and its analysis are hosted on GitHub at this URL. Any associated data is either hosted or linked to from this repository."
  },
  {
    "objectID": "pages/FAQ.html#how-can-i-reproduce-this",
    "href": "pages/FAQ.html#how-can-i-reproduce-this",
    "title": "FAQ",
    "section": "",
    "text": "Reproducing this publication is as easy as issuing a few commands from the command line. Follow this setup guide to get started."
  },
  {
    "objectID": "pages/FAQ.html#how-can-i-contribute",
    "href": "pages/FAQ.html#how-can-i-contribute",
    "title": "FAQ",
    "section": "",
    "text": "We welcome improvements to this publication! Please see our guide for contributing."
  },
  {
    "objectID": "examples/demo.html",
    "href": "examples/demo.html",
    "title": "A brief syntax demo",
    "section": "",
    "text": "This notebook demos some key features. For a more extensive resource, see Quarto’s excellent documentation."
  },
  {
    "objectID": "examples/demo.html#introduction",
    "href": "examples/demo.html#introduction",
    "title": "A brief syntax demo",
    "section": "",
    "text": "This notebook demos some key features. For a more extensive resource, see Quarto’s excellent documentation."
  },
  {
    "objectID": "examples/demo.html#text",
    "href": "examples/demo.html#text",
    "title": "A brief syntax demo",
    "section": "Text",
    "text": "Text\n\nHeaders\nh1 headers (# &lt;HEADER-TEXT&gt;) are reserved for the title of the pub, so use h2 (## &lt;HEADER-TEXT&gt;) for section titles and h3, h4, etc. for sub-sections.\n\n\nCallouts\nTo draw more attention to a piece of text, use callouts:\n\n\n\n\n\n\nImportant\n\n\n\nThe most effective way to see the rendered pub is to setup a live preview that re-renders the pub whenever you save this file. Do that with make preview.\n\n\n\n\nCitations & Footnotes\nTo cite something, add its bibtex entry to ref.bib and then cite it (Avasthi2024Early?). Here’s another (lin_evolutionary-scale_2023?). For in-depth description of available citation syntax, visit Quarto’s documentation.\nAlso, don’t forget about footnotes1.\n1 To add additional information, like what you’re reading right now, use footnotes.\nTo create a multi-paragraph footnote, indent subsequent paragraphs. Footnotes can also cite things (Avasthi2024Early?)."
  },
  {
    "objectID": "examples/demo.html#math",
    "href": "examples/demo.html#math",
    "title": "A brief syntax demo",
    "section": "Math",
    "text": "Math\nRender math2 using standard \\(\\LaTeX\\) syntax. Inline with $...$ and display with $$...$$.\n2 Quarto uses MathJax for math rendering.\\[\ne^{ \\pm i\\theta } = \\cos \\theta \\pm i\\sin \\theta\n\\tag{1}\\]\nEuler’s equation (Equation 1) is pretty."
  },
  {
    "objectID": "examples/demo.html#code",
    "href": "examples/demo.html#code",
    "title": "A brief syntax demo",
    "section": "Code",
    "text": "Code\nWrite code as you would in any Jupyter notebook.\n\ndef alertness(hours_sleep, coffees):\n    base_alertness = min(hours_sleep / 8 * 100, 100)\n    coffee_boost = min(coffees * 30, 60)\n    total = min(base_alertness + coffee_boost, 100)\n    return round(total, 1)\n\n\nprint(\"Alertness stats:\")\nprint(f\"4hrs sleep + 1 coffee: {alertness(4, 1)}%\")\nprint(f\"8hrs sleep + 0 coffee: {alertness(8, 0)}%\")\nprint(f\"2hrs sleep + 3 coffee: {alertness(2, 3)}%\")\n\nAlertness stats:\n4hrs sleep + 1 coffee: 70.0%\n8hrs sleep + 0 coffee: 100.0%\n2hrs sleep + 3 coffee: 85.0%\n\n\n\nVisibility & Placement\nSpecify per-block instructions with comments at the top of the code block.\nFold the code block (#| code-fold: true):\n\n\nSource code for this table\nimport pandas as pd\n\ndf = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [True, True, False], \"c\": [\"marco\", \"polo\", \"marco\"]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      True\n      marco\n    \n    \n      1\n      2\n      True\n      polo\n    \n    \n      2\n      3\n      False\n      marco\n    \n  \n\n\n\n\nSuppress code block visibility while retaining the cell output (#| echo: false):\n\n\n\n\n\n\nNote\n\n\n\nThe code block below runs and the output is visible, but the code itself is absent from the rendering.\n\n\n\n\nThe code that generated this print statement is hidden.\n\n\nRender the output in different places, like in the right margin (#| column: margin):\n\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      True\n      marco\n    \n    \n      1\n      2\n      True\n      polo\n    \n    \n      2\n      3\n      False\n      marco\n    \n  \n\n\n\nIn general, content placement in highly customizable. For more options, see this Quarto resource.\n\n\nAnnotation\nYou can annotate lines of code. Lines will reveal their annotation when the user hovers over the circled number on the right hand side of the code block.\n\ndef alertness(hours_sleep, coffees):\n1    base_alertness = min(hours_sleep / 8 * 100, 100)\n2    coffee_boost = min(coffees * 20, 60)\n3    total = min(base_alertness + coffee_boost, 100)\n    return round(total, 1)\n\n\n1\n\nScale to percentage, cap at 100\n\n2\n\nEach coffee adds 20%, max 60% boost\n\n3\n\nCap total at 100%\n\n\n\n\nFor details, see Quarto’s code annotation documentation.\n\n\nCodebase\nYou can choose to either fold (#| code-fold: true) or supress (#| echo: false) code snippets that distract from the narrative. However, if you’ve written an extensive amount of code, it may be more practical to define it in a package that this notebook imports from, rather than defining it in the notebook itself. This project is already set up to import from packages found in the src/ directory, so place any such code there. As an example, this code block imports code from a placeholder analysis package found at src/analysis.\n\n1from analysis import polo_if_marco\n\npolo_if_marco(\"marco\")\n\n\n1\n\nSource code\n\n\n\n\n'polo'\n\n\nIf you want to package any of your code for the purposes of simplifying this notebook, replace the contents of src/analysis/ with your own package."
  },
  {
    "objectID": "examples/demo.html#figures-tables",
    "href": "examples/demo.html#figures-tables",
    "title": "A brief syntax demo",
    "section": "Figures & Tables",
    "text": "Figures & Tables\n\nCaptions & Labeling\nIn general, if a cell output is a figure or table, you should caption and label it.\n\ndf\n\n\n\nTable 1: This is a small table.\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      True\n      marco\n    \n    \n      1\n      2\n      True\n      polo\n    \n    \n      2\n      3\n      False\n      marco\n    \n  \n\n\n\n\n\n\n\nThis is how you reference Table 1.\n\n\n\n\n\n\nNote\n\n\n\nIf the cell output is a table, the label ID should be prefixed with tbl-. If it’s a figure, prefix with fig-.\nFor example, a table could be captioned and labeled with:\n#| label: tbl-small-table\n#| tbl-cap: \"This is a small table.\"\nAnd a figure could be captioned and labeled with:\n#| label: fig-some-figure\n#| fig-cap: \"This is some figure.\"\n\n\nIf your code block produces several plots, you can subcaption each:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef random_plot():\n    plt.figure()\n    plt.scatter(np.random.rand(10), np.random.rand(10), marker=\"o\")\n    plt.tight_layout()\n    plt.show()\n    plt.close()\n\n\nfor _ in range(4):\n    random_plot()\n\n\n\n\n\n\n\n\n\n\n\n(a) This is the first plot.\n\n\n\n\n\n\n\n\n\n\n\n(b) This is the second.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) The third.\n\n\n\n\n\n\n\n\n\n\n\n(d) And finally, here’s the fourth.\n\n\n\n\n\n\n\nFigure 1: A panel of scatter plots.\n\n\n\nFigure 1 is just one example layout for multi-panel figures. For more customization options, see Quarto’s documentation on figures.\n\n\nInteractivity\nInteractive widgets can be used. For example, Plotly:\n\nimport plotly.express as px\n\ndf = px.data.gapminder()\npx.scatter(\n    df,\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    animation_frame=\"year\",\n    animation_group=\"country\",\n    size=\"pop\",\n    color=\"continent\",\n    hover_name=\"country\",\n    log_x=True,\n    size_max=55,\n    range_x=[100, 100000],\n    range_y=[25, 90],\n)\n\n                                                \n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s possible that your local preview fails to render the above widget, and you instead see something to the effect of:\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\nIf you want to see how your widget renders within the pub, run make execute and then start a new preview (make preview)."
  }
]